#### Basic ETL pipeline using Python, Spark, PostgreSQL and Airflow
#
Steps :
1) Connected Spark using Python
2) Extracted data from the PostgreSQL Database.
3) Performed required Transformation
4) After performing Transformation loaded the data again into the PostgreSQL database.
5) Used Airflow Scheduling tool 


(To keep things simple i have used 2 table schema)
